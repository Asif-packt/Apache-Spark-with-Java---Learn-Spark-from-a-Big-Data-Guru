# Apache-Spark-with-Java---Learn-Spark-from-a-Big-Data-Guru
# Apache Spark with Java - Learn Spark from a Big Data Guru [Video]
This is the code repository for [Apache Spark with Java - Learn Spark from a Big Data Guru [Video]](https://www.packtpub.com/application-development/apache-spark-java-learn-spark-big-data-guru-video), published by [Packt](https://www.packtpub.com/?utm_source=github). It contains all the supporting project files necessary to work through the video course from start to finish.
## About the Video Course
This course covers all the fundamentals of Apache Spark with Java and teaches you everything you need to know about developing Spark applications with Java. At the end of this course, you will have gained an in-depth knowledge pf Apache Spark, general big data analysis and manipulations skills. With these new skills you'll be able to help your company to adapt Apache Spark for building a big data processing pipeline and data analytics applications. This course covers 10+ hands-on big data examples. You will learn valuable knowledge on how to frame data analysis problems as Spark problems. Together we will learn examples such as aggregating NASA Apache web logs from different sources; we will explore the price trend by looking at the real estate data in California; we will write Spark applications to find out the median salary of developers in different countries through the Stack Overflow survey data; we will develop a system to analyze how maker spaces are distributed across different regions in the United Kingdom, and much more.

<H2>What You Will Learn</H2>
<DIV class=book-info-will-learn-text>
<UL>
<LI>An overview of the architecture of Apache Spark.
<LI>Work with Apache Spark's primary abstraction, resilient distributed datasets(RDDs) to
process and analyze large datasets.
<LI>Develop Apache Spark 2.0 applications using RDD transformations and actions, and Spark SQL.
<LI>Scale up Spark applications on a Hadoop YARN cluster through Amazon's Elastic MapReduce service.
<LI>Analyze structured and semi-structured data using Datasets and DataFrames, and develop a thorough understanding of Spark SQL.
<LI>Share information across different nodes on an Apache Spark cluster by broadcast variables and accumulators.
<LI> Learn best practices for working with Apache Spark in the field.</LI></UL></DIV>

## Instructions and Navigation
### Assumed Knowledge
Anyone who wants to fully understand how Apache Spark technology works and learn how Apache Spark is being used in the field. Software engineers who want to develop Apache Spark 2.0 applications using Spark Core and Spark SQL. Data scientists or data engineers who want to advance their career by improving their big data processing skills.
### Technical Requirements
This course has the following software requirements:<br/>
NA

## Related Products
* [Apache Spark in 7 Days [Video]](https://www.packtpub.com/application-development/apache-spark-7-days-video)
* [Data Science with Spark [Video]](https://www.packtpub.com/big-data-and-business-intelligence/data-science-spark-video)

* [Hands-On SQL Server 2019 Big Data Clusters with Spark [Video]](https://www.packtpub.com/application-development/hands-augmented-reality-arcore-and-unity-video?utm_source=github&utm_medium=repository&utm_campaign=9781789615722)

